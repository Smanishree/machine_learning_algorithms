{
 "metadata": {
  "name": "",
  "signature": "sha256:6467aa57e5c03250233b0ef120e6074ff988d0316a6616ba8cfbda2f50e9725f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ernesto Ezequiel Perez  \n",
      "SID 23181869  \n",
      "HW6"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem 1 - Mean Squared Error"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$J = \\frac{1}{2}\\sum_{k=1}^{n_{out}}(y_{k} - h_{k}(x))^{2}$  \n",
      "\n",
      "$v_{j} = \\sum_{i}w^{(1)}_{ij}x_{i}$  \n",
      "$\\alpha_{j} = f(v_{j}) = tanh(v_{j})$  \n",
      "$\\lambda_{k} = \\sum_{j}w^{(2)}_{jk}\\alpha_{j}$  \n",
      "$h_{k} = sigmoid(\\lambda_{k})$  \n",
      "$h_{k}(x) = sigmoid(\\sum_{j}w^{(2)}_{jk}tanh(\\sum_{i}w^{(1)}_{ij}x_{i}))$  \n",
      "\n",
      "Where $x$ is a data point, and $x_{i}$ denotes the ith feature.  \n",
      "\n",
      "$\\frac{\\partial J}{\\partial w^{(1)}_{ij}} = \\sum_{k=1}^{n_{out}}(y_{k} - h_{k})h_{k}(h_{k} - 1)w^{(2)}_{jk}(1 - tanh^{2}(\\sum_{i}w^{(1)}_{ij}x_{i}))x_{i}$  \n",
      "\n",
      "$\\frac{\\partial J}{\\partial w^{(2)}_{jk}} = \\sum_{k=1}^{n_{out}}(y_{k} - h_{k})h_{k}(h_{k} - 1)tanh(\\sum_{i}w^{(1)}_{ij}x_{i})$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem 1 - Cross Entropy Error"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$J = - \\sum_{k=1}^{n_{out}}[y_{k}ln(h_{k}(x)) + (1 - y_{k})ln(1 - h_{k}(x))]$  \n",
      "\n",
      "$\\frac{\\partial J}{\\partial w^{(1)}_{ij}} = - \\sum_{k=1}^{n_{out}}(y_{k} - h_{k})w^{(2)}_{jk}(1 - tanh^{2}(\\sum_{i}w^{(1)}_{ij}x_{i}))x_{i}$  \n",
      "\n",
      "$\\frac{\\partial J}{\\partial w^{(2)}_{jk}} = - \\sum_{k=1}^{n_{out}}(y_{k} - h_{k})tanh(\\sum_{i}w^{(1)}_{ij}x_{i})$  \n",
      "\n",
      "Where $h_{k}$ is the same as in the mean square error derivation. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problem 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import loadmat\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.preprocessing import normalize\n",
      "%matplotlib inline\n",
      "\n",
      "data = loadmat('./dataset/train.mat')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_images = [img.flatten().astype('float') for img in data['train_images'].T]\n",
      "raw_images = normalize(raw_images)\n",
      "trainImg = np.hstack((raw_images, np.ones((60000,1))))\n",
      "labels = np.asarray([ lbl[0] for lbl in data['train_labels']])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indxs = range(trainImg.shape[0])\n",
      "np.random.shuffle(indxs)\n",
      "shuffled_data = [(trainImg[i], labels[i]) for i in indxs]\n",
      "trainImg, labels = zip(*shuffled_data)\n",
      "\n",
      "trainLbls = []\n",
      "for i in labels:\n",
      "    label = [0.0]*10\n",
      "    label[i] = 1.0\n",
      "    trainLbls.append(label)\n",
      "    \n",
      "trainLbls = np.array(trainLbls)\n",
      "trainImg = np.array(trainImg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainImg.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(60000L, 785L)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigfunc(x):\n",
      "    if x.all() >= 0:\n",
      "        return 1.0 / (1.0 + np.exp(-x))\n",
      "    else:\n",
      "        z = np.exp(x)\n",
      "        return z / (1 + z)\n",
      "\n",
      "def sigPrime(z):\n",
      "    return sigfunc(z)*(1.0 - sigfunc(z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def forward(x, w1, w2):\n",
      "    v = np.dot(x, w1)\n",
      "    a = np.tanh(v)\n",
      "    lam = np.dot(a, w2)\n",
      "    hk = sigfunc(lam)\n",
      "    return a, hk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mseGradients(x, y, a, hk, w2):\n",
      "    delta1 = np.multiply((y - hk), (hk - 1.0))\n",
      "    delta2 = np.multiply(delta1, hk)\n",
      "    djdw2 = np.dot(np.array([a]).T, np.array([delta2]))\n",
      "    \n",
      "    delta3 = np.dot(delta2, w2.T)\n",
      "    delta4 = np.multiply(delta3, (1.0 - np.square(a)))\n",
      "    djdw1 = np.dot(np.array([x]).T, np.array([delta4]))\n",
      "    return djdw1, djdw2\n",
      "\n",
      "def xeGradients(x, y, a, hk, w2):\n",
      "    delta1 = hk - y\n",
      "    djdw2 = np.dot(np.array([a]).T, np.array([delta1]))\n",
      "    \n",
      "    delta2 = np.dot(delta1, w2.T)\n",
      "    delta3 = np.multiply(delta2, (1.0 - np.square(a)))\n",
      "    djdw1 = np.dot(np.array([x]).T, np.array([delta3]))\n",
      "    return  djdw1,  djdw2\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def meanSquareError(y, yHat):\n",
      "    return 0.5 * np.sum(np.square(y - yHat)) / float(y.shape[0])\n",
      "\n",
      "def crossEntropyError(y, yHat):\n",
      "    yHat = np.array([max(a, 1e-15) for a in yHat])\n",
      "    a = np.multiply(-y, np.log(yHat))\n",
      "    b = np.multiply((y - 1.0), (np.log((1.0 + 1e-15) - yHat)))\n",
      "    return np.sum(a + b) / float(y.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def trainNN(images, labels, costfunc, gradients, eta=0.3, err=0.00001, maxiters=1000000):\n",
      "    w1 = np.random.uniform(-0.1, 0.1, (785, 201))\n",
      "    w2 = np.random.uniform(-0.1, 0.1, (201, 10))\n",
      "    curr_error = 0.0\n",
      "    lowest_error = 1e+15\n",
      "    iters = 0.0\n",
      "    \n",
      "    while(iters < maxiters):\n",
      "        idx = np.random.randint(0,images.shape[0])\n",
      "        image = images[idx]\n",
      "        label = labels[idx]\n",
      "        a, yHat = forward(image, w1, w2)\n",
      "        djdw1, djdw2 = gradients(image, label, a, yHat, w2)\n",
      "        w1 -= eta*djdw1\n",
      "        w2 -= eta*djdw2\n",
      "        iters += 1.0\n",
      "        curr_error += costfunc(label, yHat)\n",
      "        if iters % 1000 == 0:\n",
      "            curr_error /= 1000.0\n",
      "            if np.absolute(lowest_error - curr_error) < err:\n",
      "                return w1, w2\n",
      "            if curr_error < lowest_error:\n",
      "                lowest_error = curr_error            \n",
      "            curr_error = 0.0\n",
      "        if iters % 150000 == 0.0:\n",
      "            eta -= 0.02\n",
      "            \n",
      "    return w1, w2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predictNN(images, w1, w2):\n",
      "    labels = []\n",
      "    \n",
      "    for img in images:\n",
      "        _, hk = forward(img, w1, w2)\n",
      "        labels.append(np.argmax(hk))\n",
      "    return labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w1, w2 = trainNN(trainImg[:50000], trainLbls[:50000], costfunc=meanSquareError, gradients=mseGradients, maxiters=10000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = predictNN(trainImg[50000:], w1, w2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hits = 0.0\n",
      "valLabels = labels[50000:]\n",
      "for i in range(len(valLabels)):\n",
      "    if valLabels[i] == pred[i]:\n",
      "        hits += 1.0\n",
      "print str(hits / float(len(pred)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.8387\n"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}